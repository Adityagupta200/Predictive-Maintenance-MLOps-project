name: Notebook Smoke

on:
  pull_request:
  push:
    branches: [master]

jobs:
  notebook-smoke:
    runs-on: ubuntu-latest
    env:
      # Use a local file-based store in CI
      MLFLOW_TRACKING_URI: file:${{ github.workspace }}/mlruns
      MLFLOW_EXPERIMENT_NAME: predictive-maintenance-cmapss
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps (incl. Jupyter)
        run: |
          python -m pip install --upgrade pip
          make setup
          pip install nbconvert jupyter

      - name: Execute notebooks
        run: |
          mkdir -p notebooks/_executed

          jupyter nbconvert --execute --to notebook \
            --ExecutePreprocessor.timeout=1800 \
            --output-dir notebooks/_executed \
            notebooks/01_mlflow_experiments.ipynb

          jupyter nbconvert --execute --to notebook \
            --ExecutePreprocessor.timeout=1800 \
            --output-dir notebooks/_executed \
            notebooks/02_compare_runs.ipynb
        # nbconvert execution is a standard way to run notebooks from the command line. [web:420]

      - name: Assert MLflow runs exist
        run: |
          python - << 'PY'
          import os
          import mlflow

          exp_name = os.environ["MLFLOW_EXPERIMENT_NAME"]
          runs = mlflow.search_runs(experiment_names=[exp_name])
          assert len(runs) > 0, f"No MLflow runs found for experiment={exp_name}"
          print("Runs found:", len(runs))
          PY

      - name: Upload executed notebooks
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: executed-notebooks
          path: notebooks/_executed

      - name: Upload mlruns (optional)
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: mlruns
          path: mlruns
