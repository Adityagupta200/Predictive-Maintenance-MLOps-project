{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b5f783c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T12:39:17.424112Z",
     "iopub.status.busy": "2026-01-23T12:39:17.423674Z",
     "iopub.status.idle": "2026-01-23T12:39:26.172389Z",
     "shell.execute_reply": "2026-01-23T12:39:26.170850Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import joblib\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f01d8451",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T12:39:26.177078Z",
     "iopub.status.busy": "2026-01-23T12:39:26.176453Z",
     "iopub.status.idle": "2026-01-23T12:39:26.315992Z",
     "shell.execute_reply": "2026-01-23T12:39:26.314415Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking_uri = file:///C:/Users/abc/Downloads/PredictiveMaintenantanceProject/mlruns\n",
      "MLFLOW_TRACKING_URI = file:///C:/Users/abc/Downloads/PredictiveMaintenantanceProject/mlruns\n",
      "Experiment = predictive-maintenance-cmapss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abc\\Downloads\\PredictiveMaintenantanceProject\\.venv\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\utils.py:178: FutureWarning: The filesystem tracking backend (e.g., './mlruns') will be deprecated in February 2026. Consider transitioning to a database backend (e.g., 'sqlite:///mlflow.db') to take advantage of the latest MLflow features. See https://github.com/mlflow/mlflow/issues/18534 for more details and migration guidance. For migrating existing data, https://github.com/mlflow/mlflow-export-import can be used.\n",
      "  return FileStore(store_uri, store_uri)\n"
     ]
    }
   ],
   "source": [
    "REPO_ROOT = Path.cwd().parent  \n",
    "tracking_uri = (REPO_ROOT / \"mlruns\").resolve().as_uri()  \n",
    "\n",
    "mlflow.set_tracking_uri(tracking_uri)\n",
    "\n",
    "experiment_name = \"predictive-maintenance-cmapss\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "print(\"tracking_uri =\", tracking_uri)\n",
    "print(\"MLFLOW_TRACKING_URI =\", mlflow.get_tracking_uri())\n",
    "print(\"Experiment =\", experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b38b7cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T12:39:26.319153Z",
     "iopub.status.busy": "2026-01-23T12:39:26.318739Z",
     "iopub.status.idle": "2026-01-23T12:39:27.676802Z",
     "shell.execute_reply": "2026-01-23T12:39:27.675206Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPO_ROOT = C:\\Users\\abc\\Downloads\\PredictiveMaintenantanceProject\n",
      "train_path = C:\\Users\\abc\\Downloads\\PredictiveMaintenantanceProject\\artifacts\\processed\\train.csv\n",
      "val_path   = C:\\Users\\abc\\Downloads\\PredictiveMaintenantanceProject\\artifacts\\processed\\val.csv\n",
      "model_path = C:\\Users\\abc\\Downloads\\PredictiveMaintenantanceProject\\models\\best_model.joblib\n",
      "target_col = RUL\n",
      "id_cols = ['engine_id', 'cycle']\n",
      "n_features = 26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coerced columns: ['fd_set']\n",
      "X_val shape: (31914, 26)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "REPO_ROOT = Path.cwd().parent\n",
    "\n",
    "if not (REPO_ROOT / \"artifacts\").exists() and (REPO_ROOT.parent / \"artifacts\").exists():\n",
    "    REPO_ROOT = REPO_ROOT.parent\n",
    "\n",
    "train_path = Path(os.getenv(\"TRAIN_CSV\", REPO_ROOT / \"artifacts\" / \"processed\" / \"train.csv\"))\n",
    "val_path = Path(os.getenv(\"VAL_CSV\", REPO_ROOT / \"artifacts\" / \"processed\" / \"val.csv\"))\n",
    "model_path = Path(os.getenv(\"MODEL_PATH\", REPO_ROOT / \"models\" / \"best_model.joblib\"))\n",
    "\n",
    "if not train_path.exists():\n",
    "    raise FileNotFoundError(f\"Missing train CSV at: {train_path}\")\n",
    "if not val_path.exists():\n",
    "    raise FileNotFoundError(f\"Missing val CSV at: {val_path}\")\n",
    "if not model_path.exists():\n",
    "    raise FileNotFoundError(f\"Missing model file at: {model_path}\")\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "val_df = pd.read_csv(val_path)\n",
    "\n",
    "# Common target names in CMAPSS pipelines\n",
    "candidate_targets = [\"RUL\", \"rul\", \"target\", \"y\"]\n",
    "target_col = next((c for c in candidate_targets if c in train_df.columns), None)\n",
    "if target_col is None:\n",
    "    raise ValueError(\n",
    "        f\"Could not infer target column. Expected one of {candidate_targets}. \"\n",
    "        f\"Columns: {list(train_df.columns)[:30]}...\"\n",
    "    )\n",
    "\n",
    "# Exclude non-feature identifier columns commonly present in CMAPSS\n",
    "id_cols = [c for c in [\"unit\", \"engine_id\", \"id\", \"cycle\", \"time_cycles\"] if c in train_df.columns]\n",
    "\n",
    "feature_cols = [c for c in train_df.columns if c not in id_cols + [target_col]]\n",
    "\n",
    "print(\"REPO_ROOT =\", REPO_ROOT)\n",
    "print(\"train_path =\", train_path)\n",
    "print(\"val_path   =\", val_path)\n",
    "print(\"model_path =\", model_path)\n",
    "\n",
    "print(\"target_col =\", target_col)\n",
    "print(\"id_cols =\", id_cols)\n",
    "print(\"n_features =\", len(feature_cols))\n",
    "\n",
    "# Ensure val has all required feature columns\n",
    "missing_in_val = [c for c in feature_cols if c not in val_df.columns]\n",
    "if missing_in_val:\n",
    "    raise ValueError(f\"val.csv missing expected feature columns: {missing_in_val[:10]}\")\n",
    "\n",
    "def _coerce_fd_like_column(df: pd.DataFrame, col: str) -> bool:\n",
    "    if col not in df.columns:\n",
    "        return False\n",
    "    # Convert 'FD001' -> 1, etc. If values don't match, fail fast with examples.\n",
    "    extracted = df[col].astype(str).str.extract(r\"(\\d+)\", expand=False)\n",
    "    if extracted.isna().any():\n",
    "        bad = df.loc[extracted.isna(), col].head(5).tolist()\n",
    "        raise ValueError(f\"{col} contains values that cannot be parsed as FD###: {bad}\")\n",
    "    df[col] = extracted.astype(int)\n",
    "    return True\n",
    "\n",
    "coerced_cols = []\n",
    "if \"fd_set\" in feature_cols:\n",
    "    _coerce_fd_like_column(train_df, \"fd_set\")\n",
    "    _coerce_fd_like_column(val_df, \"fd_set\")\n",
    "    coerced_cols.append(\"fd_set\")\n",
    "\n",
    "# Build X/y (keep the exact feature count/order expected by the trained pipeline)\n",
    "X_val = val_df[feature_cols].copy()\n",
    "y_val = val_df[target_col].copy()\n",
    "\n",
    "# Final hard check: all features must now be numeric for your current pipeline\n",
    "non_numeric = X_val.select_dtypes(exclude=\"number\").columns.tolist()\n",
    "if non_numeric:\n",
    "    sample_info = {}\n",
    "    for c in non_numeric[:10]:\n",
    "        sample_info[c] = X_val[c].dropna().astype(str).unique()[:5].tolist()\n",
    "    raise ValueError(\n",
    "        \"Non-numeric feature columns still present (model pipeline likely expects numeric). \"\n",
    "        f\"Columns={non_numeric}. Samples={sample_info}\"\n",
    "    )\n",
    "\n",
    "print(\"Coerced columns:\", coerced_cols)\n",
    "print(\"X_val shape:\", X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35520f06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T12:39:27.679917Z",
     "iopub.status.busy": "2026-01-23T12:39:27.679502Z",
     "iopub.status.idle": "2026-01-23T12:39:27.687683Z",
     "shell.execute_reply": "2026-01-23T12:39:27.686198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric feature cols: []\n"
     ]
    }
   ],
   "source": [
    "# Identify non-numeric feature columns (these will break median/mean imputers)\n",
    "non_numeric = X_val.select_dtypes(exclude=\"number\").columns.tolist()\n",
    "print(\"Non-numeric feature cols:\", non_numeric)\n",
    "\n",
    "if non_numeric:\n",
    "    for c in non_numeric[:10]:\n",
    "        print(c, \"sample values:\", X_val[c].dropna().astype(str).unique()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "856d169c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T12:39:27.691604Z",
     "iopub.status.busy": "2026-01-23T12:39:27.691105Z",
     "iopub.status.idle": "2026-01-23T12:39:55.032015Z",
     "shell.execute_reply": "2026-01-23T12:39:55.030640Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/23 18:09:28 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh(<full-path-to-git-executable>)\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial message can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|silent|none|n|0: for no message or exception\n",
      "    - warn|w|warning|log|l|1: for a warning message (logging level CRITICAL, displayed by default)\n",
      "    - error|e|exception|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/23 18:09:29 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mae': 118.58621978759766, 'rmse': 145.0765624915858}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "model = joblib.load(model_path)\n",
    "\n",
    "y_pred = model.predict(X_val[feature_cols].to_numpy())\n",
    "\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "\n",
    "with mlflow.start_run(run_name=\"baseline-cmapss\"):\n",
    "    mlflow.log_param(\"model_path\", str(model_path))\n",
    "    mlflow.log_param(\"target_col\", target_col)\n",
    "    mlflow.log_param(\"id_cols\", \",\".join(id_cols))\n",
    "    mlflow.log_param(\"n_features\", int(len(feature_cols)))\n",
    "    mlflow.log_param(\"features\", \",\".join(feature_cols[:50]))  # keep logs compact\n",
    "\n",
    "    mlflow.log_metric(\"mae\", float(mae))\n",
    "    mlflow.log_metric(\"rmse\", float(rmse))\n",
    "\n",
    "    mlflow.sklearn.log_model(model, artifact_path=\"model\")\n",
    "\n",
    "print({\"mae\": mae, \"rmse\": rmse})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
