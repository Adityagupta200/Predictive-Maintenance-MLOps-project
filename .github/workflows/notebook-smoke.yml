name: Notebook Smoke

on:
  pull_request:
  push:
    branches: [master]
  workflow_dispatch:

jobs:
  notebook-smoke:
    runs-on: ubuntu-latest
    env:
      MLFLOW_TRACKING_URI: file:${{ github.workspace }}/mlruns
      MLFLOW_EXPERIMENT_NAME: predictive-maintenance-cmapss

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps (incl. Jupyter)
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          make setup
          pip install nbconvert jupyter

      - name: Prepare notebook inputs (generate artifacts)
        run: |
          set -euo pipefail

          mkdir -p artifacts/processed models

          # 1) Try Makefile targets if they exist 
          if [ ! -f artifacts/processed/train.csv ] || [ ! -f artifacts/processed/val.csv ]; then
            if make -n preprocess >/dev/null 2>&1; then
              make preprocess
            elif make -n pipeline >/dev/null 2>&1; then
              make pipeline
            fi
          fi

          if [ ! -f models/best_model.joblib ]; then
            if make -n train >/dev/null 2>&1; then
              make train
            fi
          fi

          # 2) Fallback: try python modules if Make targets aren't available
          if [ ! -f artifacts/processed/train.csv ] || [ ! -f artifacts/processed/val.csv ]; then
            if [ -f params.yaml ]; then
              python -m src.validate_data --config params.yaml || true
              python -m src.data_preprocessing --config params.yaml || true
            else
              python -m src.validate_data || true
              python -m src.data_preprocessing || true
            fi
          fi

          if [ ! -f models/best_model.joblib ]; then
            if [ -f params.yaml ]; then
              python -m src.train_model --config params.yaml || true
            else
              python -m src.train_model || true
            fi
          fi

          # 3) Hard fail with a clear message if still missing
          test -f artifacts/processed/train.csv || (echo "Missing artifacts/processed/train.csv (pipeline didn't produce it)" && exit 1)
          test -f artifacts/processed/val.csv   || (echo "Missing artifacts/processed/val.csv (pipeline didn't produce it)" && exit 1)
          test -f models/best_model.joblib      || (echo "Missing models/best_model.joblib (training didn't produce it)" && exit 1)

          # Export paths so the notebook uses these even if its cwd logic differs
          echo "TRAIN_CSV=${GITHUB_WORKSPACE}/artifacts/processed/train.csv" >> "$GITHUB_ENV"
          echo "VAL_CSV=${GITHUB_WORKSPACE}/artifacts/processed/val.csv" >> "$GITHUB_ENV"
          echo "MODEL_PATH=${GITHUB_WORKSPACE}/models/best_model.joblib" >> "$GITHUB_ENV"

      - name: Execute notebooks
        run: |
          set -euo pipefail
          mkdir -p notebooks/_executed

          # nbconvert is a standard way to execute notebooks non-interactively. [web:775]
          jupyter nbconvert --execute --to notebook \
            --ExecutePreprocessor.timeout=1800 \
            --output-dir notebooks/_executed \
            notebooks/01_mlflow_experiments.ipynb

          jupyter nbconvert --execute --to notebook \
            --ExecutePreprocessor.timeout=1800 \
            --output-dir notebooks/_executed \
            notebooks/02_compare_runs.ipynb

      - name: Assert MLflow runs exist
        run: |
          set -euo pipefail
          python - << 'PY'
          import os
          import mlflow

          mlflow.set_tracking_uri(os.environ["MLFLOW_TRACKING_URI"])
          mlflow.set_experiment(os.environ["MLFLOW_EXPERIMENT_NAME"])

          runs = mlflow.search_runs(experiment_names=[os.environ["MLFLOW_EXPERIMENT_NAME"]])
          assert len(runs) > 0, "No MLflow runs found (notebooks may not have logged any runs)"
          print("Runs found:", len(runs))
          PY

      - name: Upload executed notebooks
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: executed-notebooks
          path: notebooks/_executed

      - name: Upload mlruns
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: mlruns
          path: mlruns
