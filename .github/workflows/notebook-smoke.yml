name: Notebook Smoke

on:
  pull_request:
  push:
    branches: [master]
  workflow_dispatch:

jobs:
  notebook-smoke:
    runs-on: ubuntu-latest
    env:
      # Tracking backend (SQLite) -> avoids the filesystem-tracking-backend deprecation.
      MLFLOW_TRACKING_URI: sqlite:///${{ github.workspace }}/mlflow.db

      # Experiment + artifact layout
      MLFLOW_EXPERIMENT_NAME: predictive-maintenance-cmapss
      MLFLOW_MODEL_NAME: model
      MLFLOW_ARTIFACT_ROOT: ${{ github.workspace }}/mlflow-artifacts

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps (incl. Jupyter + MLflow helpers)
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          make setup
          python -m pip install nbconvert jupyter ipykernel mlflow joblib

      - name: Clean MLflow state (CI only)
        run: |
          set -euo pipefail
          rm -f mlflow.db || true
          rm -rf "$MLFLOW_ARTIFACT_ROOT" || true
          rm -rf mlruns || true
          mkdir -p "$MLFLOW_ARTIFACT_ROOT"

      - name: Initialize MLflow experiment (before notebooks)
        run: |
          set -euo pipefail
          python - << 'PY'
          import os
          from pathlib import Path
          import mlflow

          mlflow.set_tracking_uri(os.environ["MLFLOW_TRACKING_URI"])

          exp_name = os.environ["MLFLOW_EXPERIMENT_NAME"]
          artifact_root = Path(os.environ["MLFLOW_ARTIFACT_ROOT"]).resolve()

          exp = mlflow.get_experiment_by_name(exp_name)
          if exp is None:
              # Use file: URI for maximum compatibility across MLflow versions.
              exp_id = mlflow.create_experiment(exp_name, artifact_location=f"file:{artifact_root}")
              exp = mlflow.get_experiment(exp_id)
              print(f"Created experiment: {exp_name} ({exp.experiment_id}) artifact_location={exp.artifact_location}")
          else:
              print(f"Experiment exists: {exp_name} ({exp.experiment_id}) artifact_location={exp.artifact_location}")

          # Export experiment id for potential debugging/use.
          with open(os.environ["GITHUB_ENV"], "a", encoding="utf-8") as f:
              f.write(f"MLFLOW_EXPERIMENT_ID={exp.experiment_id}\n")
          PY

      - name: Prepare notebook inputs (generate artifacts)
        run: |
          set -euo pipefail
          mkdir -p artifacts/processed models

          # Generate required local inputs for Notebook 01
          if [ ! -f artifacts/processed/train.csv ] || [ ! -f artifacts/processed/val.csv ]; then
            if make -n preprocess >/dev/null 2>&1; then
              make preprocess
            elif make -n pipeline >/dev/null 2>&1; then
              make pipeline
            fi
          fi

          if [ ! -f models/best_model.joblib ]; then
            if make -n train >/dev/null 2>&1; then
              make train
            fi
          fi

          # Hard fail with clear message if still missing
          test -f artifacts/processed/train.csv || (echo "Missing artifacts/processed/train.csv" && exit 1)
          test -f artifacts/processed/val.csv || (echo "Missing artifacts/processed/val.csv" && exit 1)
          test -f models/best_model.joblib || (echo "Missing models/best_model.joblib" && exit 1)

          # Export explicit paths for notebooks
          echo "TRAIN_CSV=${GITHUB_WORKSPACE}/artifacts/processed/train.csv" >> "$GITHUB_ENV"
          echo "VAL_CSV=${GITHUB_WORKSPACE}/artifacts/processed/val.csv" >> "$GITHUB_ENV"
          echo "MODEL_PATH=${GITHUB_WORKSPACE}/models/best_model.joblib" >> "$GITHUB_ENV"

      - name: Execute notebook 01 (logs MLflow runs)
        run: |
          set -euo pipefail
          mkdir -p notebooks/_executed
          jupyter nbconvert --execute --to notebook \
            --ExecutePreprocessor.timeout=1800 \
            --output-dir notebooks/_executed \
            notebooks/01_mlflow_experiments.ipynb

      - name: Ensure at least one run has a logged model (fallback if Notebook 01 didn't)
        run: |
          set -euo pipefail
          python - << 'PY'
          import os
          from pathlib import Path
          from urllib.parse import urlparse, unquote

          import joblib
          import mlflow
          import mlflow.sklearn
          from mlflow.tracking import MlflowClient

          def artifact_uri_to_path(uri: str) -> Path:
              # Handles file:/... and plain absolute paths.
              if uri.startswith("file:"):
                  return Path(unquote(urlparse(uri).path))
              return Path(uri)

          def has_model_on_disk(artifact_uri: str, model_name: str) -> bool:
              root = artifact_uri_to_path(artifact_uri)
              # Most common layout: <artifact_uri>/<model_name>/MLmodel
              p1 = root / model_name / "MLmodel"
              # Some repos might put models under "models/<name>"
              p2 = root / "models" / model_name / "MLmodel"
              return p1.exists() or p2.exists()

          mlflow.set_tracking_uri(os.environ["MLFLOW_TRACKING_URI"])
          mlflow.set_experiment(os.environ["MLFLOW_EXPERIMENT_NAME"])

          client = MlflowClient()
          exp = mlflow.get_experiment_by_name(os.environ["MLFLOW_EXPERIMENT_NAME"])
          if exp is None:
              raise SystemExit("Experiment not found")

          model_name = os.environ["MLFLOW_MODEL_NAME"]

          # Look for any existing run that already has a model artifact on disk.
          runs = client.search_runs(
              experiment_ids=[exp.experiment_id],
              filter_string="",
              order_by=["start_time DESC"],
              max_results=200,
          )

          for r in runs:
              stage = getattr(r.info, "lifecycle_stage", "active")
              if stage == "deleted":
                  continue
              if has_model_on_disk(r.info.artifact_uri, model_name):
                  print("Found existing run with model artifact; no fallback needed.")
                  raise SystemExit(0)

          # Otherwise create fallback run and log model using artifact_path (most compatible).
          model_path = Path(os.environ["MODEL_PATH"])
          if not model_path.exists():
              raise SystemExit(f"MODEL_PATH does not exist: {model_path}")

          model = joblib.load(model_path)

          with mlflow.start_run(run_name="ci-fallback-model") as run:
              mlflow.log_param("fallback_reason", "notebook_01_did_not_log_model")

              # Use artifact_path for maximum MLflow version compatibility.
              mlflow.sklearn.log_model(model, artifact_path=model_name)

              mlflow.log_metric("ci_fallback", 1.0)
              run_id = run.info.run_id

          run_info = client.get_run(run_id).info
          if not has_model_on_disk(run_info.artifact_uri, model_name):
              print(f"Fallback run artifact_uri={run_info.artifact_uri}")
              raise SystemExit(f"Fallback run did not produce '{model_name}' artifact as expected.")

          print(f"Created fallback run with model: {run_id}")
          PY

      - name: Prune runs missing model artifact (disk check; backend-agnostic)
        run: |
          set -euo pipefail
          python - << 'PY'
          import os
          import shutil
          from pathlib import Path
          from urllib.parse import urlparse, unquote

          import mlflow
          from mlflow.tracking import MlflowClient

          def artifact_uri_to_path(uri: str) -> Path:
              if uri.startswith("file:"):
                  return Path(unquote(urlparse(uri).path))
              return Path(uri)

          def has_model_on_disk(artifact_uri: str, model_name: str) -> bool:
              root = artifact_uri_to_path(artifact_uri)
              p1 = root / model_name / "MLmodel"
              p2 = root / "models" / model_name / "MLmodel"
              return p1.exists() or p2.exists()

          mlflow.set_tracking_uri(os.environ["MLFLOW_TRACKING_URI"])
          exp = mlflow.get_experiment_by_name(os.environ["MLFLOW_EXPERIMENT_NAME"])
          if exp is None:
              raise SystemExit("Experiment not found")

          client = MlflowClient()
          model_name = os.environ["MLFLOW_MODEL_NAME"]

          runs = client.search_runs(
              experiment_ids=[exp.experiment_id],
              filter_string="",
              order_by=["start_time DESC"],
              max_results=500,
          )

          kept = 0
          removed = 0

          for r in runs:
              stage = getattr(r.info, "lifecycle_stage", "active")
              if stage == "deleted":
                  continue

              if has_model_on_disk(r.info.artifact_uri, model_name):
                  kept += 1
                  continue

              # Delete run from tracking store
              client.delete_run(r.info.run_id)
              removed += 1

              # Best-effort delete artifacts on disk (only if local path)
              art_path = artifact_uri_to_path(r.info.artifact_uri)
              if art_path.is_absolute() and art_path.exists():
                  shutil.rmtree(art_path, ignore_errors=True)

          print(f"Pruned runs: removed={removed}, kept_with_model={kept}")
          if kept == 0:
              raise SystemExit(f"No MLflow runs with artifacts/{model_name} found after fallback.")
          PY

      - name: Execute notebook 02 (loads best model from MLflow)
        run: |
          set -euo pipefail
          jupyter nbconvert --execute --to notebook \
            --ExecutePreprocessor.timeout=1800 \
            --output-dir notebooks/_executed \
            notebooks/02_compare_runs.ipynb

      - name: Upload executed notebooks
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: executed-notebooks
          path: notebooks/_executed

      - name: Upload MLflow artifacts + DB
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: mlflow-tracking
          path: |
            mlflow.db
            mlflow-artifacts
            mlruns
